---
title: "R Notebook"
---

# Script for dada2 processing

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# Naming convention
## large.variable.A-B.names
## regular_variable_names
## CONSTANT_NAMES
## funtionNames
## ClassNames

setwd("./Working Files/")
knitr::opts_knit$set(root.dir = normalizePath("./Working Files/")) 
```

```{r}
# Initialising
getwd()
library(dada2); packageVersion("dada2")
library(ggplot2); packageVersion("ggplot2")
library(Biostrings); packageVersion("Biostrings")
library(purrr); packageVersion("purrr")
library(tidyverse); packageVersion("tidyverse")
```

# PS-PL 16S
```{r}
getwd()
path <- "../../04_Data/Coral_PNG_16s/PS-PL-Coral-16s" # CHANGE ME to the directory containing the fastq files after unzipping.
list.files(path)
```
```{r}
# Forward and reverse fastq filenames have format: SAMPLENAME_1.fastq and SAMPLENAME_2.fastq
fnFs <- sort(list.files(path, pattern="_1.fastq.gz", full.names = TRUE))
fnRs <- sort(list.files(path, pattern="_2.fastq.gz", full.names = TRUE))
# Extract sample names, assuming filenames have format: SAMPLENAME_1.fastq
sample.names <- sapply(strsplit(basename(fnFs), "_1.fastq.gz"), `[`, 1)
```

## Quality Profiles
```{r}
plotQualityProfile(fnFs[11:12])
ggsave("./Outputs/Quality plot F - PS-PL-PNG-16s.png", width = 6, height = 4)
plotQualityProfile(fnRs[11:12])
ggsave("./Outputs/Quality plot R - PS-PL-PNG-16s.png", width = 6, height = 4)
```
We trim at 250, 150.

## Filtering and Trimming
```{r}
# Place filtered files in filtered/ subdirectory
filtFs <- file.path(path, "filtered", paste0(sample.names, "_F_filt.fastq.gz"))
filtRs <- file.path(path, "filtered", paste0(sample.names, "_R_filt.fastq.gz"))
names(filtFs) <- sample.names
names(filtRs) <- sample.names

truncLenR1 <- 250
truncLenR2 <- 150
maxEER1 <- 2 # Default 2
maxEER2 <- 2 # Default 2

out <- filterAndTrim(fnFs, filtFs, fnRs, filtRs, truncLen=c(truncLenR1,truncLenR2),
                     maxN=0, maxEE=c(maxEER1,maxEER2), truncQ=2, rm.phix=TRUE,
                     compress=TRUE, multithread=TRUE) # On Windows set multithread=FALSE
head(out)
```

## Learn the Error Rates
```{r}
errF <- learnErrors(filtFs, multithread=TRUE) 
errR <- learnErrors(filtRs, multithread=TRUE) 
plotErrors(errF, nominalQ=FALSE)
ggsave("./Outputs/ErrF plot - PS-PL-PNG-16s.png", width = 6, height = 4)
plotErrors(errR, nominalQ=FALSE)
ggsave("./Outputs/ErrR plot - PS-PL-PNG-16s.png", width = 6, height = 4)
```

## Dereplication, Sample Inference, and Merging Reads
```{r}
# Loop taking care of dereplication, sample inference and merging paired reads
dadaFs <- vector("list", length(sample.names))
dadaRs <- vector("list", length(sample.names))
mergers <- vector("list", length(sample.names))
names(dadaFs) <- sample.names
names(dadaRs) <- sample.names
names(mergers) <- sample.names
for (sam in sample.names){
  cat("Processing:", sam, "\n")
  derepF <- derepFastq(filtFs[[sam]], verbose = TRUE)
  derepR <- derepFastq(filtRs[[sam]], verbose = TRUE)
  dadaFs[[sam]] <- dada(derepF, err=errF, multithread = TRUE)
  dadaRs[[sam]] <- dada(derepR, err=errR, multithread = TRUE)
  mergers[[sam]] <- mergePairs(dadaFs[[sam]], derepF, dadaRs[[sam]], derepR, verbose = TRUE)
}
head(mergers[[1]])
```

## Construct sequence table
```{r}
seqtab <- makeSequenceTable(mergers)
dim(seqtab) # 227 85537
saveRDS(seqtab, "./Outputs/seqtabs/seqtab_raw_PS-PL-PNG-16s.RDS")

## Inspect distribution of sequence lengths
table(nchar(getSequences(seqtab)))
```

## Remove chimeras
```{r}
seqtab.nochim <- removeBimeraDenovo(seqtab, method="consensus", multithread=TRUE, verbose=TRUE) 
dim(seqtab.nochim)
saveRDS(seqtab.nochim, "./Outputs/seqtabs/seqtab_nochim_PS-PL-PNG-16s.RDS")

sum(seqtab.nochim)/sum(seqtab)
```

## Track reads through pipeline
```{r}
getN <- function(x) sum(getUniques(x))
track <- cbind(out, sapply(dadaFs, getN), sapply(dadaRs, getN), sapply(mergers, getN), rowSums(seqtab.nochim))
# If processing a single sample, remove the sapply calls: e.g. replace sapply(dadaFs, getN) with getN(dadaFs)
colnames(track) <- c("input", "filtered", "denoisedF", "denoisedR", "merged", "nonchim")
rownames(track) <- sample.names
track
write.csv(track, file = "./Outputs/dada2track_PS-PL-PNG-16s.csv")
```
```{r}
# Removing objects not required ahead to conserve RAM because some of the next steps are memory intensive
rm(dadaFs)
rm(dadaRs)
rm(derepF)
rm(derepR)
rm(errF)
rm(errR)
rm(mergers)
rm(out)
rm(seqtab)
```
```{r}
# Resume Point
#seqtab.nochim <- readRDS("./Outputs/Coral_16s/seqtabs/seqtab_nochim_PS-PL-PNG-16s.RDS")
```

## Import metadata
```{r}
## Update this code section according to own run.
meta = read.csv("../../Resources/metadata-16s.csv", stringsAsFactors = FALSE)
row.names(meta) <- NULL
row.names(meta) <- meta$sampleName
row.names(seqtab.nochim)

# reorder metadata
meta = meta[order(row.names(meta)),]
meta = meta[rownames(meta) %in% rownames(seqtab.nochim),]
identical(rownames(meta), rownames(seqtab.nochim))
```

## Remove contaminants using controls
```{r}
library(decontam); packageVersion("decontam")

# Find control samples (extraction negatives)
meta$controls <- meta$site == "Blank"

# Find contaminants
contams = isContaminant(seqtab.nochim, neg = meta$controls, normalize = TRUE)
table(contams$contaminant)
write.csv(contams, file = "./Outputs/likely_contaminants-PS-PL-PNG-16s.csv", row.names = TRUE)

# Remove them
seqtab.nochim = seqtab.nochim[meta$controls == FALSE,]
meta = meta[meta$controls == FALSE,]

saveRDS(meta, file = "./Outputs/final_meta-PS-PL-PNG-16s.RDS")
```

## Assign Taxonomy
```{r}
taxa <- assignTaxonomy(seqtab.nochim, "../../04_Data/tax/silva_nr99_v138.1_train_set.fa.gz", multithread=TRUE) # CHANGE ME to taxa file location.
# taxa <- addSpecies(taxa, "../../04_Data/tax/silva_species_assignment_v138.1.fa.gz") # Species level if required but memory intensive.

write.csv(as.data.frame(seqtab.nochim), file = "./Outputs/SeqTable_no-chimera_no-contams-PS-PL-PNG-16s.csv", row.names = TRUE, quote = FALSE)
saveRDS(seqtab.nochim, file = "./Outputs/seqtabs/clean_dada2_seqtable-PS-PL-PNG-16s.RDS")
saveRDS(taxa, file = "./Outputs/Silva_Taxonomy_from_dada2-PS-PL-PNG-16s.RDS")

# Removing Mitochondria and Chloroplast as we are only analysing bacteria
#seqtab.nochim <- readRDS(file = "./Outputs/Coral_16s/seqtabs/clean_dada2_seqtable-PS-PL-PNG-16s.RDS")
#taxa <- readRDS(file = "./Outputs/Coral_16s/Silva_Taxonomy_from_dada2-PS-PL-PNG-16s.RDS")

# Remove non-bacterial samples
is.bacteria <- taxa[,"Kingdom"] %in% "Bacteria"
taxa <- taxa[is.bacteria,]
seqtab.bacteria <- seqtab.nochim[,is.bacteria]

# Remove "mitochondria" taxa
is.mitochon <- taxa[,"Family"] %in% "Mitochondria"
taxa <- taxa[!is.mitochon,]
seqtab.nomitochon <- seqtab.bacteria[,!is.mitochon]

# Remove "Chloroplast" taxa
is.chloro <- taxa[,"Order"] %in% "Chloroplast"
taxa <- taxa[!is.chloro,]
seqtab.nochloro <- seqtab.nomitochon[,!is.chloro]

is.chloro <- taxa[,"Class"] %in% "Chloroplast"
taxa <- taxa[!is.chloro,]
seqtab.nochloro <- seqtab.nochloro[,!is.chloro]

saveRDS(seqtab.nochloro, file = "./Outputs/seqtabs/final_clean_dada2_seqtable-PS-PL-PNG-16s.RDS")
saveRDS(taxa, file = "./Outputs/final_Silva_Taxonomy_from_dada2-PS-PL-PNG-16s.RDS")
```

## Adding Read Counts for new steps
```{r}
nochim <- rowSums(seqtab.nochim)
bacteria <- rowSums(seqtab.bacteria)
nomitochon <- rowSums(seqtab.nomitochon)
nochloro <- rowSums(seqtab.nochloro)
netloss <- (nochim-nochloro)/nochim
track_decontam <- data.frame(nochim, bacteria, nomitochon, nochloro, netloss)
write.csv(track_decontam, file = "./Outputs/read_counts_at_each_step_after_decontam-PS-PL-PNG-16s.csv", row.names = TRUE)
track_decontam
```

# DH-PA 16S
```{r}
getwd()
path <- "../../04_Data/Coral_PNG_16s/DH-PA-Coral-16s" # CHANGE ME to the directory containing the fastq files after unzipping.
list.files(path)
```
```{r}
# Forward and reverse fastq filenames have format: SAMPLENAME_1.fastq and SAMPLENAME_2.fastq
fnFs <- sort(list.files(path, pattern="_1.fastq.gz", full.names = TRUE))
fnRs <- sort(list.files(path, pattern="_2.fastq.gz", full.names = TRUE))
# Extract sample names, assuming filenames have format: SAMPLENAME_1.fastq
sample.names <- sapply(strsplit(basename(fnFs), "_1.fastq.gz"), `[`, 1)
```

## Quality Profiles
```{r}
plotQualityProfile(fnFs[11:12])
ggsave("./Outputs/Quality plot F - DH-PA-PNG-16s.png", width = 6, height = 4)
plotQualityProfile(fnRs[11:12])
ggsave("./Outputs/Quality plot R - DH-PA-PNG-16s.png", width = 6, height = 4)
```
We trim at 250, 150. The reverse reads appear very short than expected.

## Filtering and Trimming
```{r}
# Place filtered files in filtered/ subdirectory
filtFs <- file.path(path, "filtered", paste0(sample.names, "_F_filt.fastq.gz"))
filtRs <- file.path(path, "filtered", paste0(sample.names, "_R_filt.fastq.gz"))
names(filtFs) <- sample.names
names(filtRs) <- sample.names

truncLenR1 <- 250
truncLenR2 <- 150
maxEER1 <- 2 # Default 2
maxEER2 <- 2 # Default 2

out <- filterAndTrim(fnFs, filtFs, fnRs, filtRs, truncLen=c(truncLenR1,truncLenR2),
                     maxN=0, maxEE=c(maxEER1,maxEER2), truncQ=2, rm.phix=TRUE,
                     compress=TRUE, multithread=TRUE) # On Windows set multithread=FALSE
head(out)
```

## Learn the Error Rates
```{r}
errF <- learnErrors(filtFs, multithread=TRUE) 
errR <- learnErrors(filtRs, multithread=TRUE) 
plotErrors(errF, nominalQ=FALSE)
ggsave("./Outputs/ErrF plot - DH-PA-PNG-16s.png", width = 6, height = 4)
plotErrors(errR, nominalQ=FALSE)
ggsave("./Outputs/ErrR plot - DH-PA-PNG-16s.png", width = 6, height = 4)
```

## Dereplication, Sample Inference, and Merging Reads
```{r}
# Loop taking care of dereplication, sample inference and merging paired reads
dadaFs <- vector("list", length(sample.names))
dadaRs <- vector("list", length(sample.names))
mergers <- vector("list", length(sample.names))
names(dadaFs) <- sample.names
names(dadaRs) <- sample.names
names(mergers) <- sample.names
for (sam in sample.names){
  cat("Processing:", sam, "\n")
  derepF <- derepFastq(filtFs[[sam]], verbose = TRUE)
  derepR <- derepFastq(filtRs[[sam]], verbose = TRUE)
  dadaFs[[sam]] <- dada(derepF, err=errF, multithread = TRUE)
  dadaRs[[sam]] <- dada(derepR, err=errR, multithread = TRUE)
  mergers[[sam]] <- mergePairs(dadaFs[[sam]], derepF, dadaRs[[sam]], derepR, verbose = TRUE)
}
head(mergers[[1]])
```

## Construct sequence table
```{r}
seqtab <- makeSequenceTable(mergers)
dim(seqtab) # 227 85537
saveRDS(seqtab, "./Outputs/seqtabs/seqtab_raw_DH-PA-PNG-16s.RDS")

## Inspect distribution of sequence lengths
table(nchar(getSequences(seqtab)))
```

## Remove chimeras
```{r}
seqtab.nochim <- removeBimeraDenovo(seqtab, method="consensus", multithread=TRUE, verbose=TRUE) 
dim(seqtab.nochim)
saveRDS(seqtab.nochim, "./Outputs/seqtabs/seqtab_nochim_DH-PA-PNG-16s.RDS")

sum(seqtab.nochim)/sum(seqtab)
```

## Track reads through pipeline
```{r}
getN <- function(x) sum(getUniques(x))
track <- cbind(out, sapply(dadaFs, getN), sapply(dadaRs, getN), sapply(mergers, getN), rowSums(seqtab.nochim))
# If processing a single sample, remove the sapply calls: e.g. replace sapply(dadaFs, getN) with getN(dadaFs)
colnames(track) <- c("input", "filtered", "denoisedF", "denoisedR", "merged", "nonchim")
rownames(track) <- sample.names
track
write.csv(track, file = "./Outputs/dada2track_DH-PA-PNG-16s.csv")
```
```{r}
# Removing objects not required ahead to conserve RAM because some of the next steps are memory intensive
rm(dadaFs)
rm(dadaRs)
rm(derepF)
rm(derepR)
rm(errF)
rm(errR)
rm(mergers)
rm(out)
rm(seqtab)
```
```{r}
# Resume Point
#seqtab.nochim <- readRDS("./Outputs/Coral_16s/seqtabs/seqtab_nochim_DH-PA-PNG-16s.RDS")
```

## Import metadata
```{r}
## Update this code section according to own run.
meta = read.csv("../../Resources/metadata-16s.csv", stringsAsFactors = FALSE)
row.names(meta) <- NULL
row.names(meta) <- meta$sampleName
row.names(seqtab.nochim)

# reorder metadata
meta = meta[order(row.names(meta)),]
meta = meta[rownames(meta) %in% rownames(seqtab.nochim),]
identical(rownames(meta), rownames(seqtab.nochim))
```

## Remove contaminants using controls
```{r}
library(decontam); packageVersion("decontam")

# Find controlsamples (extraction negatives)
meta$controls <- meta$site == "Blank"

# Find contaminants
contams = isContaminant(seqtab.nochim, neg = meta$controls, normalize = TRUE)
table(contams$contaminant)
write.csv(contams, file = "./Outputs/likely_contaminants-DH-PA-PNG-16s.csv", row.names = TRUE)

# Remove them
seqtab.nochim = seqtab.nochim[meta$controls == FALSE,]
meta = meta[meta$controls == FALSE,]

saveRDS(meta, file = "./Outputs/final_meta-DH-PA-PNG-16s.RDS")
```

## Assign Taxonomy
```{r}
taxa <- assignTaxonomy(seqtab.nochim, "../../04_Data/tax/silva_nr99_v138.1_train_set.fa.gz", multithread=TRUE) # CHANGE ME to taxa file location.
# taxa <- addSpecies(taxa, "../../04_Data/tax/silva_species_assignment_v138.1.fa.gz") # Species level if required but memory intensive.

write.csv(as.data.frame(seqtab.nochim), file = "./Outputs/SeqTable_no-chimera_no-contams-DH-PA-PNG-16s.csv", row.names = TRUE, quote = FALSE)
saveRDS(seqtab.nochim, file = "./Outputs/seqtabs/clean_dada2_seqtable-DH-PA-PNG-16s.RDS")
saveRDS(taxa, file = "./Outputs/Silva_Taxonomy_from_dada2-DH-PA-PNG-16s.RDS")

# Removing Mitochondria and Chloroplast as we are only analysing bacteria
#seqtab.nochim <- readRDS(file = "./Outputs/Coral_16s/seqtabs/clean_dada2_seqtable-DH-PA-PNG-16s.RDS")
#taxa <- readRDS(file = "./Outputs/Coral_16s/Silva_Taxonomy_from_dada2-DH-PA-PNG-16s.RDS")

# Remove non-bacterial samples
is.bacteria <- taxa[,"Kingdom"] %in% "Bacteria"
taxa <- taxa[is.bacteria,]
seqtab.bacteria <- seqtab.nochim[,is.bacteria]

# Remove "mitochondria" taxa
is.mitochon <- taxa[,"Family"] %in% "Mitochondria"
taxa <- taxa[!is.mitochon,]
seqtab.nomitochon <- seqtab.bacteria[,!is.mitochon]

# Remove "Chloroplast" taxa
is.chloro <- taxa[,"Order"] %in% "Chloroplast"
taxa <- taxa[!is.chloro,]
seqtab.nochloro <- seqtab.nomitochon[,!is.chloro]

is.chloro <- taxa[,"Class"] %in% "Chloroplast"
taxa <- taxa[!is.chloro,]
seqtab.nochloro <- seqtab.nochloro[,!is.chloro]

saveRDS(seqtab.nochloro, file = "./Outputs/seqtabs/final_clean_dada2_seqtable-DH-PA-PNG-16s.RDS")
saveRDS(taxa, file = "./Outputs/final_Silva_Taxonomy_from_dada2-DH-PA-PNG-16s.RDS")
```

## Adding Read Counts for new steps
```{r}
nochim <- rowSums(seqtab.nochim)
bacteria <- rowSums(seqtab.bacteria)
nomitochon <- rowSums(seqtab.nomitochon)
nochloro <- rowSums(seqtab.nochloro)
netloss <- (nochim-nochloro)/nochim
track_decontam <- data.frame(nochim, bacteria, nomitochon, nochloro, netloss)
write.csv(track_decontam, file = "./Outputs/read_counts_at_each_step_after_decontam-DH-PA-PNG-16s.csv", row.names = TRUE)
track_decontam
```

# EW Coral Samples 16S

# EW-1
```{r}
getwd()
path <- "../../04_Data/2308KMI-0001" # CHANGE ME to the directory containing the fastq files after unzipping.
list.files(path)
```
```{r}
# Forward and reverse fastq filenames have format: SAMPLENAME_1.fastq and SAMPLENAME_2.fastq
fnFs <- sort(list.files(path, pattern="_1.fastq.gz", full.names = TRUE))
fnRs <- sort(list.files(path, pattern="_2.fastq.gz", full.names = TRUE))
# Extract sample names, assuming filenames have format: SAMPLENAME_1.fastq
sample.names <- sapply(strsplit(basename(fnFs), "_1.fastq.gz"), `[`, 1)
```

## Quality Profiles
```{r}
plotQualityProfile(fnFs[11:12])
ggsave("./Outputs/Quality plot F - EW-1-16s.png", width = 6, height = 4)
plotQualityProfile(fnRs[11:12])
ggsave("./Outputs/Quality plot R - EW-1-16s.png", width = 6, height = 4)
```
We trim at 250, 150.

## Filtering and Trimming
```{r}
# Place filtered files in filtered/ subdirectory
filtFs <- file.path(path, "filtered", paste0(sample.names, "_F_filt.fastq.gz"))
filtRs <- file.path(path, "filtered", paste0(sample.names, "_R_filt.fastq.gz"))
names(filtFs) <- sample.names
names(filtRs) <- sample.names

truncLenR1 <- 250
truncLenR2 <- 150
maxEER1 <- 2 # Default 2
maxEER2 <- 2 # Default 2

out <- filterAndTrim(fnFs, filtFs, fnRs, filtRs, truncLen=c(truncLenR1,truncLenR2),
                     maxN=0, maxEE=c(maxEER1,maxEER2), truncQ=2, rm.phix=TRUE,
                     compress=TRUE, multithread=TRUE) # On Windows set multithread=FALSE
head(out)
```

## Learn the Error Rates
```{r}
errF <- learnErrors(filtFs, multithread=TRUE) 
errR <- learnErrors(filtRs, multithread=TRUE) 
plotErrors(errF, nominalQ=FALSE)
ggsave("./Outputs/ErrF plot - EW-1-16s.png", width = 6, height = 4)
plotErrors(errR, nominalQ=FALSE)
ggsave("./Outputs/ErrR plot - EW-1-16s.png", width = 6, height = 4)
```

## Dereplication, Sample Inference, and Merging Reads
```{r}
# Loop taking care of dereplication, sample inference and merging paired reads
dadaFs <- vector("list", length(sample.names))
dadaRs <- vector("list", length(sample.names))
mergers <- vector("list", length(sample.names))
names(dadaFs) <- sample.names
names(dadaRs) <- sample.names
names(mergers) <- sample.names
for (sam in sample.names){
  cat("Processing:", sam, "\n")
  derepF <- derepFastq(filtFs[[sam]], verbose = TRUE)
  derepR <- derepFastq(filtRs[[sam]], verbose = TRUE)
  dadaFs[[sam]] <- dada(derepF, err=errF, multithread = TRUE)
  dadaRs[[sam]] <- dada(derepR, err=errR, multithread = TRUE)
  mergers[[sam]] <- mergePairs(dadaFs[[sam]], derepF, dadaRs[[sam]], derepR, verbose = TRUE)
}
head(mergers[[1]])
```

## Construct sequence table
```{r}
seqtab <- makeSequenceTable(mergers)
dim(seqtab) # 227 85537
saveRDS(seqtab, "./Outputs/seqtabs/seqtab_raw_EW-1-16s.RDS")

## Inspect distribution of sequence lengths
table(nchar(getSequences(seqtab)))
```

## Remove chimeras
```{r}
seqtab.nochim <- removeBimeraDenovo(seqtab, method="consensus", multithread=TRUE, verbose=TRUE) 
dim(seqtab.nochim)
saveRDS(seqtab.nochim, "./Outputs/seqtabs/seqtab_nochim_EW-1-16s.RDS")

sum(seqtab.nochim)/sum(seqtab)
```

## Track reads through pipeline
```{r}
getN <- function(x) sum(getUniques(x))
track <- cbind(out, sapply(dadaFs, getN), sapply(dadaRs, getN), sapply(mergers, getN), rowSums(seqtab.nochim))
# If processing a single sample, remove the sapply calls: e.g. replace sapply(dadaFs, getN) with getN(dadaFs)
colnames(track) <- c("input", "filtered", "denoisedF", "denoisedR", "merged", "nonchim")
rownames(track) <- sample.names
track
write.csv(track, file = "./Outputs/dada2track_EW-1-16s.csv")
```
```{r}
# Removing objects not required ahead to conserve RAM because some of the next steps are memory intensive
rm(dadaFs)
rm(dadaRs)
rm(derepF)
rm(derepR)
rm(errF)
rm(errR)
rm(mergers)
rm(out)
rm(seqtab)
```
```{r}
# Resume Point
#seqtab.nochim <- readRDS("./Outputs/Coral_16s/seqtabs/seqtab_nochim_EW-1-16s.RDS")
```

## Import metadata
```{r}
## Update this code section according to own run.
meta = read.csv("../../Resources/metadata-16s.csv", stringsAsFactors = FALSE)
row.names(meta) <- NULL
row.names(meta) <- meta$sampleName
row.names(seqtab.nochim)

# reorder metadata
meta = meta[order(row.names(meta)),]
meta = meta[rownames(meta) %in% rownames(seqtab.nochim),]
identical(rownames(meta), rownames(seqtab.nochim))
```

## Remove contaminants using controls
```{r}
library(decontam); packageVersion("decontam")

# Find control samples (extraction negatives)
meta$controls <- meta$site == "Blank"

# Find contaminants
contams = isContaminant(seqtab.nochim, neg = meta$controls, normalize = TRUE)
table(contams$contaminant)
write.csv(contams, file = "./Outputs/likely_contaminants-EW-1-16s.csv", row.names = TRUE)

# Remove them
seqtab.nochim = seqtab.nochim[meta$controls == FALSE,]
meta = meta[meta$controls == FALSE,]

saveRDS(meta, file = "./Outputs/final_meta-EW-1-16s.RDS")
```

## Assign Taxonomy
```{r}
taxa <- assignTaxonomy(seqtab.nochim, "../../04_Data/tax/silva_nr99_v138.1_train_set.fa.gz", multithread=TRUE) # CHANGE ME to taxa file location.
# taxa <- addSpecies(taxa, "../../04_Data/tax/silva_species_assignment_v138.1.fa.gz") # Species level if required but memory intensive.

write.csv(as.data.frame(seqtab.nochim), file = "./Outputs/SeqTable_no-chimera_no-contams-EW-1-16s.csv", row.names = TRUE, quote = FALSE)
saveRDS(seqtab.nochim, file = "./Outputs/seqtabs/clean_dada2_seqtable-EW-1-16s.RDS")
saveRDS(taxa, file = "./Outputs/Silva_Taxonomy_from_dada2-EW-1-16s.RDS")

# Removing Mitochondria and Chloroplast as we are only analysing bacteria
#seqtab.nochim <- readRDS(file = "./Outputs/Coral_16s/seqtabs/clean_dada2_seqtable-EW-1-16s.RDS")
#taxa <- readRDS(file = "./Outputs/Coral_16s/Silva_Taxonomy_from_dada2-EW-1-16s.RDS")

# Remove non-bacterial samples
is.bacteria <- taxa[,"Kingdom"] %in% "Bacteria"
taxa <- taxa[is.bacteria,]
seqtab.bacteria <- seqtab.nochim[,is.bacteria]

# Remove "mitochondria" taxa
is.mitochon <- taxa[,"Family"] %in% "Mitochondria"
taxa <- taxa[!is.mitochon,]
seqtab.nomitochon <- seqtab.bacteria[,!is.mitochon]

# Remove "Chloroplast" taxa
is.chloro <- taxa[,"Order"] %in% "Chloroplast"
taxa <- taxa[!is.chloro,]
seqtab.nochloro <- seqtab.nomitochon[,!is.chloro]

is.chloro <- taxa[,"Class"] %in% "Chloroplast"
taxa <- taxa[!is.chloro,]
seqtab.nochloro <- seqtab.nochloro[,!is.chloro]

saveRDS(seqtab.nochloro, file = "./Outputs/seqtabs/final_clean_dada2_seqtable-EW-1-16s.RDS")
saveRDS(taxa, file = "./Outputs/final_Silva_Taxonomy_from_dada2-EW-1-16s.RDS")
```

## Adding Read Counts for new steps
```{r}
nochim <- rowSums(seqtab.nochim)
bacteria <- rowSums(seqtab.bacteria)
nomitochon <- rowSums(seqtab.nomitochon)
nochloro <- rowSums(seqtab.nochloro)
netloss <- (nochim-nochloro)/nochim
track_decontam <- data.frame(nochim, bacteria, nomitochon, nochloro, netloss)
write.csv(track_decontam, file = "./Outputs/read_counts_at_each_step_after_decontam-EW-1-16s.csv", row.names = TRUE)
track_decontam
```


# EW-2
```{r}
getwd()
path <- "../../04_Data/2308KMI-0002" # CHANGE ME to the directory containing the fastq files after unzipping.
list.files(path)
```
```{r}
# Forward and reverse fastq filenames have format: SAMPLENAME_1.fastq and SAMPLENAME_2.fastq
fnFs <- sort(list.files(path, pattern="_1.fastq.gz", full.names = TRUE))
fnRs <- sort(list.files(path, pattern="_2.fastq.gz", full.names = TRUE))
# Extract sample names, assuming filenames have format: SAMPLENAME_1.fastq
sample.names <- sapply(strsplit(basename(fnFs), "_1.fastq.gz"), `[`, 1)
```

## Quality Profiles
```{r}
plotQualityProfile(fnFs[11:12])
ggsave("./Outputs/Quality plot F - EW-2-16s.png", width = 6, height = 4)
plotQualityProfile(fnRs[11:12])
ggsave("./Outputs/Quality plot R - EW-2-16s.png", width = 6, height = 4)
```
We trim at 250, 150.

## Filtering and Trimming
```{r}
# Place filtered files in filtered/ subdirectory
filtFs <- file.path(path, "filtered", paste0(sample.names, "_F_filt.fastq.gz"))
filtRs <- file.path(path, "filtered", paste0(sample.names, "_R_filt.fastq.gz"))
names(filtFs) <- sample.names
names(filtRs) <- sample.names

truncLenR1 <- 250
truncLenR2 <- 150
maxEER1 <- 2 # Default 2
maxEER2 <- 2 # Default 2

out <- filterAndTrim(fnFs, filtFs, fnRs, filtRs, truncLen=c(truncLenR1,truncLenR2),
                     maxN=0, maxEE=c(maxEER1,maxEER2), truncQ=2, rm.phix=TRUE,
                     compress=TRUE, multithread=TRUE) # On Windows set multithread=FALSE
head(out)
```

PA_EW2_Blank_02 lost in filtering

## Learn the Error Rates
```{r}
errF <- learnErrors(filtFs, multithread=TRUE) 
errR <- learnErrors(filtRs, multithread=TRUE) 
plotErrors(errF, nominalQ=FALSE)
ggsave("./Outputs/ErrF plot - EW-2-16s.png", width = 6, height = 4)
plotErrors(errR, nominalQ=FALSE)
ggsave("./Outputs/ErrR plot - EW-2-16s.png", width = 6, height = 4)
```



## Dereplication, Sample Inference, and Merging Reads
```{r}
# To handle missing filtered files
sample.names <- sapply(strsplit(basename(fnFs), "_1.fastq.gz"), `[`, 1)
exists <- file.exists(filtFs)
sample.names <- sample.names[exists]

# Loop taking care of dereplication, sample inference and merging paired reads
dadaFs <- vector("list", length(sample.names))
dadaRs <- vector("list", length(sample.names))
mergers <- vector("list", length(sample.names))
names(dadaFs) <- sample.names
names(dadaRs) <- sample.names
names(mergers) <- sample.names

for (sam in sample.names){
  cat("Processing:", sam, "\n")
  derepF <- derepFastq(filtFs[[sam]], verbose = TRUE)
  derepR <- derepFastq(filtRs[[sam]], verbose = TRUE)
  dadaFs[[sam]] <- dada(derepF, err=errF, multithread = TRUE)
  dadaRs[[sam]] <- dada(derepR, err=errR, multithread = TRUE)
  mergers[[sam]] <- mergePairs(dadaFs[[sam]], derepF, dadaRs[[sam]], derepR, verbose = TRUE)
}
head(mergers[[1]])
```

## Construct sequence table
```{r}
seqtab <- makeSequenceTable(mergers)
dim(seqtab) # 227 85537
saveRDS(seqtab, "./Outputs/seqtabs/seqtab_raw_EW-2-16s.RDS")

## Inspect distribution of sequence lengths
table(nchar(getSequences(seqtab)))
```

## Remove chimeras
```{r}
seqtab.nochim <- removeBimeraDenovo(seqtab, method="consensus", multithread=TRUE, verbose=TRUE) 
dim(seqtab.nochim)
saveRDS(seqtab.nochim, "./Outputs/seqtabs/seqtab_nochim_EW-2-16s.RDS")

sum(seqtab.nochim)/sum(seqtab)
```

## Track reads through pipeline
```{r}
getN <- function(x) sum(getUniques(x))
track <- cbind(out[exists,], sapply(dadaFs, getN), sapply(dadaRs, getN), sapply(mergers, getN), rowSums(seqtab.nochim))
# If processing a single sample, remove the sapply calls: e.g. replace sapply(dadaFs, getN) with getN(dadaFs)
colnames(track) <- c("input", "filtered", "denoisedF", "denoisedR", "merged", "nonchim")
rownames(track) <- sample.names
track
write.csv(track, file = "./Outputs/dada2track_EW-2-16s.csv")
```
```{r}
# Removing objects not required ahead to conserve RAM because some of the next steps are memory intensive
rm(dadaFs)
rm(dadaRs)
rm(derepF)
rm(derepR)
rm(errF)
rm(errR)
rm(mergers)
rm(out)
rm(seqtab)
```
```{r}
# Resume Point
#seqtab.nochim <- readRDS("./Outputs/seqtabs/seqtab_nochim_EW-2-16s.RDS")
```

## Import metadata
```{r}
## Update this code section according to own run.
meta = read.csv("../../Resources/metadata-16s.csv", stringsAsFactors = FALSE)
row.names(meta) <- NULL
row.names(meta) <- meta$sampleName
row.names(seqtab.nochim)

# reorder metadata
meta = meta[order(row.names(meta)),]
meta = meta[rownames(meta) %in% rownames(seqtab.nochim),]
identical(rownames(meta), rownames(seqtab.nochim))
```

## Remove contaminants using controls
```{r}
library(decontam); packageVersion("decontam")

# Find control samples (extraction negatives)
meta$controls <- meta$site == "Blank"

# Find contaminants
contams = isContaminant(seqtab.nochim, neg = meta$controls, normalize = TRUE)
table(contams$contaminant)
write.csv(contams, file = "./Outputs/likely_contaminants-EW-2-16s.csv", row.names = TRUE)

# Remove them
seqtab.nochim = seqtab.nochim[meta$controls == FALSE,]
meta = meta[meta$controls == FALSE,]

saveRDS(meta, file = "./Outputs/final_meta-EW-2-16s.RDS")
```

## Assign Taxonomy
```{r}
taxa <- assignTaxonomy(seqtab.nochim, "../../04_Data/tax/silva_nr99_v138.1_train_set.fa.gz", multithread=TRUE) # CHANGE ME to taxa file location.
# taxa <- addSpecies(taxa, "../../04_Data/tax/silva_species_assignment_v138.1.fa.gz") # Species level if required but memory intensive.

write.csv(as.data.frame(seqtab.nochim), file = "./Outputs/SeqTable_no-chimera_no-contams-EW-2-16s.csv", row.names = TRUE, quote = FALSE)
saveRDS(seqtab.nochim, file = "./Outputs/seqtabs/clean_dada2_seqtable-EW-2-16s.RDS")
saveRDS(taxa, file = "./Outputs/Silva_Taxonomy_from_dada2-EW-2-16s.RDS")

# Removing Mitochondria and Chloroplast as we are only analysing bacteria
#seqtab.nochim <- readRDS(file = "./Outputs/Coral_16s/seqtabs/clean_dada2_seqtable-EW-2-16s.RDS")
#taxa <- readRDS(file = "./Outputs/Coral_16s/Silva_Taxonomy_from_dada2-EW-2-16s.RDS")

# Remove non-bacterial samples
is.bacteria <- taxa[,"Kingdom"] %in% "Bacteria"
taxa <- taxa[is.bacteria,]
seqtab.bacteria <- seqtab.nochim[,is.bacteria]

# Remove "mitochondria" taxa
is.mitochon <- taxa[,"Family"] %in% "Mitochondria"
taxa <- taxa[!is.mitochon,]
seqtab.nomitochon <- seqtab.bacteria[,!is.mitochon]

# Remove "Chloroplast" taxa
is.chloro <- taxa[,"Order"] %in% "Chloroplast"
taxa <- taxa[!is.chloro,]
seqtab.nochloro <- seqtab.nomitochon[,!is.chloro]

is.chloro <- taxa[,"Class"] %in% "Chloroplast"
taxa <- taxa[!is.chloro,]
seqtab.nochloro <- seqtab.nochloro[,!is.chloro]

saveRDS(seqtab.nochloro, file = "./Outputs/seqtabs/final_clean_dada2_seqtable-EW-2-16s.RDS")
saveRDS(taxa, file = "./Outputs/final_Silva_Taxonomy_from_dada2-EW-2-16s.RDS")
```

## Adding Read Counts for new steps
```{r}
nochim <- rowSums(seqtab.nochim)
bacteria <- rowSums(seqtab.bacteria)
nomitochon <- rowSums(seqtab.nomitochon)
nochloro <- rowSums(seqtab.nochloro)
netloss <- (nochim-nochloro)/nochim
track_decontam <- data.frame(nochim, bacteria, nomitochon, nochloro, netloss)
write.csv(track_decontam, file = "./Outputs/read_counts_at_each_step_after_decontam-EW-2-16s.csv", row.names = TRUE)
track_decontam
```


# Mangrove PNG 16s

# AA
```{r}
getwd()
path <- "../../04_Data/Mangrove_16s/AA-16s" # CHANGE ME to the directory containing the fastq files after unzipping.
list.files(path)
```
```{r}
getwd()
# Forward and reverse fastq filenames have format: SAMPLENAME_1.fastq and SAMPLENAME_2.fastq
fnFs <- sort(list.files(path, pattern="_1.fastq.gz", full.names = TRUE))
fnRs <- sort(list.files(path, pattern="_2.fastq.gz", full.names = TRUE))
# Extract sample names, assuming filenames have format: SAMPLENAME_1.fastq
sample.names <- sapply(strsplit(basename(fnFs), "_1.fastq.gz"), `[`, 1)
```

## Quality Profiles
```{r}
plotQualityProfile(fnFs[11:12])
ggsave("./Outputs/Quality plot F - AA-16s.png", width = 6, height = 4)
plotQualityProfile(fnRs[11:12])
ggsave("./Outputs/Quality plot R - AA-16s.png", width = 6, height = 4)
```
We trim at 250, 250.

## Filtering and Trimming
```{r}
# Place filtered files in filtered/ subdirectory
filtFs <- file.path(path, "filtered", paste0(sample.names, "_F_filt.fastq.gz"))
filtRs <- file.path(path, "filtered", paste0(sample.names, "_R_filt.fastq.gz"))
names(filtFs) <- sample.names
names(filtRs) <- sample.names

truncLenR1 <- 250
truncLenR2 <- 250
maxEER1 <- 2 # Default 2
maxEER2 <- 2 # Default 2

out <- filterAndTrim(fnFs, filtFs, fnRs, filtRs, truncLen=c(truncLenR1,truncLenR2),
                     maxN=0, maxEE=c(maxEER1,maxEER2), truncQ=2, rm.phix=TRUE,
                     compress=TRUE, multithread=TRUE) # On Windows set multithread=FALSE
head(out)
```

## Learn the Error Rates
```{r}
errF <- learnErrors(filtFs, multithread=TRUE) 
errR <- learnErrors(filtRs, multithread=TRUE) 
plotErrors(errF, nominalQ=FALSE)
ggsave("./Outputs/ErrF plot - AA-16s.png", width = 6, height = 4)
plotErrors(errR, nominalQ=FALSE)
ggsave("./Outputs/ErrR plot - AA-16s.png", width = 6, height = 4)
```

## Dereplication, Sample Inference, and Merging Reads
```{r}
# Loop taking care of dereplication, sample inference and merging paired reads
dadaFs <- vector("list", length(sample.names))
dadaRs <- vector("list", length(sample.names))
mergers <- vector("list", length(sample.names))
names(dadaFs) <- sample.names
names(dadaRs) <- sample.names
names(mergers) <- sample.names
for (sam in sample.names){
  cat("Processing:", sam, "\n")
  derepF <- derepFastq(filtFs[[sam]], verbose = TRUE)
  derepR <- derepFastq(filtRs[[sam]], verbose = TRUE)
  dadaFs[[sam]] <- dada(derepF, err=errF, multithread = TRUE)
  dadaRs[[sam]] <- dada(derepR, err=errR, multithread = TRUE)
  mergers[[sam]] <- mergePairs(dadaFs[[sam]], derepF, dadaRs[[sam]], derepR, verbose = TRUE)
}
head(mergers[[1]])
```

## Construct sequence table
```{r}
seqtab <- makeSequenceTable(mergers)
dim(seqtab) # 227 85537
saveRDS(seqtab, "./Outputs/seqtabs/seqtab_raw_AA-16s.RDS")

## Inspect distribution of sequence lengths
table(nchar(getSequences(seqtab)))
```

## Remove chimeras
```{r}
seqtab.nochim <- removeBimeraDenovo(seqtab, method="consensus", multithread=TRUE, verbose=TRUE) 
dim(seqtab.nochim)
saveRDS(seqtab.nochim, "./Outputs/seqtabs/seqtab_nochim_AA-16s.RDS")

sum(seqtab.nochim)/sum(seqtab)
```

## Track reads through pipeline
```{r}
getN <- function(x) sum(getUniques(x))
track <- cbind(out, sapply(dadaFs, getN), sapply(dadaRs, getN), sapply(mergers, getN), rowSums(seqtab.nochim))
# If processing a single sample, remove the sapply calls: e.g. replace sapply(dadaFs, getN) with getN(dadaFs)
colnames(track) <- c("input", "filtered", "denoisedF", "denoisedR", "merged", "nonchim")
rownames(track) <- sample.names
track
write.csv(track, file = "./Outputs/dada2track_AA-16s.csv")
```
```{r}
# Removing objects not required ahead to conserve RAM because some of the next steps are memory intensive
rm(dadaFs)
rm(dadaRs)
rm(derepF)
rm(derepR)
rm(errF)
rm(errR)
rm(mergers)
rm(out)
rm(seqtab)
```
```{r}
# Resume Point
#seqtab.nochim <- readRDS("./Outputs/Mangrove_16s/seqtabs/seqtab_nochim_AA-16s.RDS")
```

## Import metadata
```{r}
## Update this code section according to own run.
meta = read.csv("../../Resources/metadata-16s.csv", stringsAsFactors = FALSE)
row.names(meta) <- NULL
row.names(meta) <- meta$sampleName
row.names(seqtab.nochim)

# reorder metadata
meta = meta[order(row.names(meta)),]
meta = meta[rownames(meta) %in% rownames(seqtab.nochim),]
identical(rownames(meta), rownames(seqtab.nochim))
```

## Remove contaminants using controls
```{r}
library(decontam); packageVersion("decontam")

# Find controlsamples (extraction negatives)
meta$controls <- meta$site == "Blank"

# Find contaminants
contams = isContaminant(seqtab.nochim, neg = meta$controls, normalize = TRUE)
table(contams$contaminant)
write.csv(contams, file = "./Outputs/likely_contaminants-AA-16s.csv", row.names = TRUE)

# Remove them
seqtab.nochim = seqtab.nochim[meta$controls == FALSE,]
meta = meta[meta$controls == FALSE,]

saveRDS(meta, file = "./Outputs/final_meta-AA-16s.RDS")
```

## Assign Taxonomy
```{r}
taxa <- assignTaxonomy(seqtab.nochim, "../../04_Data/tax/silva_nr99_v138.1_train_set.fa.gz", multithread=TRUE) # CHANGE ME to taxa file location.
# taxa <- addSpecies(taxa, "../../04_Data/tax/silva_species_assignment_v138.1.fa.gz") # Species level if required but memory intensive.

write.csv(as.data.frame(seqtab.nochim), file = "./Outputs/SeqTable_no-chimera_no-contams-AA-16s.csv", row.names = TRUE, quote = FALSE)
saveRDS(seqtab.nochim, file = "./Outputs/seqtabs/clean_dada2_seqtable-AA-16s.RDS")
saveRDS(taxa, file = "./Outputs/Silva_Taxonomy_from_dada2-AA-16s.RDS")

# Removing Mitochondria and Chloroplast as we are only analysing bacteria
#seqtab.nochim <- readRDS(file = "./Outputs/Mangrove_16s/seqtabs/clean_dada2_seqtable-AA-16s.RDS")
#taxa <- readRDS(file = "./Outputs/Mangrove_16s/Silva_Taxonomy_from_dada2-AA-16s.RDS")

# Remove non-bacterial samples
is.bacteria <- taxa[,"Kingdom"] %in% "Bacteria"
taxa <- taxa[is.bacteria,]
seqtab.bacteria <- seqtab.nochim[,is.bacteria]

# Remove "mitochondria" taxa
is.mitochon <- taxa[,"Family"] %in% "Mitochondria"
taxa <- taxa[!is.mitochon,]
seqtab.nomitochon <- seqtab.bacteria[,!is.mitochon]

# Remove "Chloroplast" taxa
is.chloro <- taxa[,"Order"] %in% "Chloroplast"
taxa <- taxa[!is.chloro,]
seqtab.nochloro <- seqtab.nomitochon[,!is.chloro]

is.chloro <- taxa[,"Class"] %in% "Chloroplast"
taxa <- taxa[!is.chloro,]
seqtab.nochloro <- seqtab.nochloro[,!is.chloro]

saveRDS(seqtab.nochloro, file = "./Outputs/seqtabs/final_clean_dada2_seqtable-AA-16s.RDS")
saveRDS(taxa, file = "./Outputs/final_Silva_Taxonomy_from_dada2-AA-16s.RDS")
```

## Adding Read Counts for new steps
```{r}
nochim <- rowSums(seqtab.nochim)
bacteria <- rowSums(seqtab.bacteria)
nomitochon <- rowSums(seqtab.nomitochon)
nochloro <- rowSums(seqtab.nochloro)
netloss <- (nochim-nochloro)/nochim
track_decontam <- data.frame(nochim, bacteria, nomitochon, nochloro, netloss)
write.csv(track_decontam, file = "./Outputs/read_counts_at_each_step_after_decontam-AA-16s.csv", row.names = TRUE)
track_decontam
```


# SA
```{r}
getwd()
path <- "../../04_Data/Mangrove_16s/SA-16s" # CHANGE ME to the directory containing the fastq files after unzipping.
list.files(path)
```
```{r}
getwd()
# Forward and reverse fastq filenames have format: SAMPLENAME_1.fastq and SAMPLENAME_2.fastq
fnFs <- sort(list.files(path, pattern="_1.fastq.gz", full.names = TRUE))
fnRs <- sort(list.files(path, pattern="_2.fastq.gz", full.names = TRUE))
# Extract sample names, assuming filenames have format: SAMPLENAME_1.fastq
sample.names <- sapply(strsplit(basename(fnFs), "_1.fastq.gz"), `[`, 1)
```

## Quality Profiles
```{r}
plotQualityProfile(fnFs[11:12])
ggsave("./Outputs/Quality plot F - SA-16s.png", width = 6, height = 4)
plotQualityProfile(fnRs[11:12])
ggsave("./Outputs/Quality plot R - SA-16s.png", width = 6, height = 4)
```
We trim at 250, 250.

## Filtering and Trimming
```{r}
# Place filtered files in filtered/ subdirectory
filtFs <- file.path(path, "filtered", paste0(sample.names, "_F_filt.fastq.gz"))
filtRs <- file.path(path, "filtered", paste0(sample.names, "_R_filt.fastq.gz"))
names(filtFs) <- sample.names
names(filtRs) <- sample.names

truncLenR1 <- 250
truncLenR2 <- 250
maxEER1 <- 2 # Default 2
maxEER2 <- 2 # Default 2

out <- filterAndTrim(fnFs, filtFs, fnRs, filtRs, truncLen=c(truncLenR1,truncLenR2),
                     maxN=0, maxEE=c(maxEER1,maxEER2), truncQ=2, rm.phix=TRUE,
                     compress=TRUE, multithread=TRUE) # On Windows set multithread=FALSE
head(out)
```

## Learn the Error Rates
```{r}
errF <- learnErrors(filtFs, multithread=TRUE) 
errR <- learnErrors(filtRs, multithread=TRUE) 
plotErrors(errF, nominalQ=FALSE)
ggsave("./Outputs/ErrF plot - SA-16s.png", width = 6, height = 4)
plotErrors(errR, nominalQ=FALSE)
ggsave("./Outputs/ErrR plot - SA-16s.png", width = 6, height = 4)
```

## Dereplication, Sample Inference, and Merging Reads
```{r}
# Loop taking care of dereplication, sample inference and merging paired reads
dadaFs <- vector("list", length(sample.names))
dadaRs <- vector("list", length(sample.names))
mergers <- vector("list", length(sample.names))
names(dadaFs) <- sample.names
names(dadaRs) <- sample.names
names(mergers) <- sample.names
for (sam in sample.names){
  cat("Processing:", sam, "\n")
  derepF <- derepFastq(filtFs[[sam]], verbose = TRUE)
  derepR <- derepFastq(filtRs[[sam]], verbose = TRUE)
  dadaFs[[sam]] <- dada(derepF, err=errF, multithread = TRUE)
  dadaRs[[sam]] <- dada(derepR, err=errR, multithread = TRUE)
  mergers[[sam]] <- mergePairs(dadaFs[[sam]], derepF, dadaRs[[sam]], derepR, verbose = TRUE)
}
head(mergers[[1]])
```

## Construct sequence table
```{r}
seqtab <- makeSequenceTable(mergers)
dim(seqtab) # 227 85537
saveRDS(seqtab, "./Outputs/seqtabs/seqtab_raw_SA-16s.RDS")

## Inspect distribution of sequence lengths
table(nchar(getSequences(seqtab)))
```

## Remove chimeras
```{r}
seqtab.nochim <- removeBimeraDenovo(seqtab, method="consensus", multithread=TRUE, verbose=TRUE) 
dim(seqtab.nochim)
saveRDS(seqtab.nochim, "./Outputs/seqtabs/seqtab_nochim_SA-16s.RDS")

sum(seqtab.nochim)/sum(seqtab)
```

## Track reads through pipeline
```{r}
getN <- function(x) sum(getUniques(x))
track <- cbind(out, sapply(dadaFs, getN), sapply(dadaRs, getN), sapply(mergers, getN), rowSums(seqtab.nochim))
# If processing a single sample, remove the sapply calls: e.g. replace sapply(dadaFs, getN) with getN(dadaFs)
colnames(track) <- c("input", "filtered", "denoisedF", "denoisedR", "merged", "nonchim")
rownames(track) <- sample.names
track
write.csv(track, file = "./Outputs/dada2track_SA-16s.csv")
```
```{r}
# Removing objects not required ahead to conserve RAM because some of the next steps are memory intensive
rm(dadaFs)
rm(dadaRs)
rm(derepF)
rm(derepR)
rm(errF)
rm(errR)
rm(mergers)
rm(out)
rm(seqtab)
```
```{r}
# Resume Point
#seqtab.nochim <- readRDS("./Outputs/Mangrove_16s/seqtabs/seqtab_nochim_SA-16s.RDS")
```

## Import metadata
```{r}
## Update this code section according to own run.
meta = read.csv("../../Resources/metadata-16s.csv", stringsAsFactors = FALSE)
row.names(meta) <- NULL
row.names(meta) <- meta$sampleName
row.names(seqtab.nochim)

# reorder metadata
meta = meta[order(row.names(meta)),]
meta = meta[rownames(meta) %in% rownames(seqtab.nochim),]
identical(rownames(meta), rownames(seqtab.nochim))
```

## Remove contaminants using controls
```{r}
library(decontam); packageVersion("decontam")

# Find controlsamples (extraction negatives)
meta$controls <- meta$site == "Blank"

# Find contaminants
contams = isContaminant(seqtab.nochim, neg = meta$controls, normalize = TRUE)
table(contams$contaminant)
write.csv(contams, file = "./Outputs/likely_contaminants-SA-16s.csv", row.names = TRUE)

# Remove them
seqtab.nochim = seqtab.nochim[meta$controls == FALSE,]
meta = meta[meta$controls == FALSE,]

saveRDS(meta, file = "./Outputs/final_meta-SA-16s.RDS")
```

## Assign Taxonomy
```{r}
taxa <- assignTaxonomy(seqtab.nochim, "../../04_Data/tax/silva_nr99_v138.1_train_set.fa.gz", multithread=TRUE) # CHANGE ME to taxa file location.
# taxa <- addSpecies(taxa, "../../04_Data/tax/silva_species_assignment_v138.1.fa.gz") # Species level if required but memory intensive.

write.csv(as.data.frame(seqtab.nochim), file = "./Outputs/SeqTable_no-chimera_no-contams-SA-16s.csv", row.names = TRUE, quote = FALSE)
saveRDS(seqtab.nochim, file = "./Outputs/seqtabs/clean_dada2_seqtable-SA-16s.RDS")
saveRDS(taxa, file = "./Outputs/Silva_Taxonomy_from_dada2-SA-16s.RDS")

# Removing Mitochondria and Chloroplast as we are only analysing bacteria
#seqtab.nochim <- readRDS(file = "./Outputs/Mangrove_16s/seqtabs/clean_dada2_seqtable-SA-16s.RDS")
#taxa <- readRDS(file = "./Outputs/Mangrove_16s/Silva_Taxonomy_from_dada2-SA-16s.RDS")

# Remove non-bacterial samples
is.bacteria <- taxa[,"Kingdom"] %in% "Bacteria"
taxa <- taxa[is.bacteria,]
seqtab.bacteria <- seqtab.nochim[,is.bacteria]

# Remove "mitochondria" taxa
is.mitochon <- taxa[,"Family"] %in% "Mitochondria"
taxa <- taxa[!is.mitochon,]
seqtab.nomitochon <- seqtab.bacteria[,!is.mitochon]

# Remove "Chloroplast" taxa
is.chloro <- taxa[,"Order"] %in% "Chloroplast"
taxa <- taxa[!is.chloro,]
seqtab.nochloro <- seqtab.nomitochon[,!is.chloro]

is.chloro <- taxa[,"Class"] %in% "Chloroplast"
taxa <- taxa[!is.chloro,]
seqtab.nochloro <- seqtab.nochloro[,!is.chloro]

saveRDS(seqtab.nochloro, file = "./Outputs/seqtabs/final_clean_dada2_seqtable-SA-16s.RDS")
saveRDS(taxa, file = "./Outputs/final_Silva_Taxonomy_from_dada2-SA-16s.RDS")
```

## Adding Read Counts for new steps
```{r}
nochim <- rowSums(seqtab.nochim)
bacteria <- rowSums(seqtab.bacteria)
nomitochon <- rowSums(seqtab.nomitochon)
nochloro <- rowSums(seqtab.nochloro)
netloss <- (nochim-nochloro)/nochim
track_decontam <- data.frame(nochim, bacteria, nomitochon, nochloro, netloss)
write.csv(track_decontam, file = "./Outputs/read_counts_at_each_step_after_decontam-SA-16s.csv", row.names = TRUE)
track_decontam
```


# SA_2
```{r}
getwd()
path <- "../../04_Data/Mangrove_PNG_16s/2012KMI-0002/Primer_Removed" # CHANGE ME to the directory containing the fastq files after unzipping.
list.files(path)
```
```{r}
getwd()
# Forward and reverse fastq filenames have format: SAMPLENAME_R1.fastq and SAMPLENAME_R2.fastq
fnFs <- sort(list.files(path, pattern="_R1.fastq.gz", full.names = TRUE))
fnRs <- sort(list.files(path, pattern="_R2.fastq.gz", full.names = TRUE))
# Extract sample names, assuming filenames have format: SAMPLENAME_R1.fastq
sample.names <- sapply(strsplit(basename(fnFs), "_R1.fastq.gz"), `[`, 1)
```

## Quality Profiles
```{r}
plotQualityProfile(fnFs[11:12])
ggsave("./Outputs/Quality plot F - SA_2-16s.png", width = 6, height = 4)
plotQualityProfile(fnRs[11:12])
ggsave("./Outputs/Quality plot R - SA_2-16s.png", width = 6, height = 4)
```
We trim at 250, 250.

## Filtering and Trimming
```{r}
# Place filtered files in filtered/ subdirectory
filtFs <- file.path(path, "filtered", paste0(sample.names, "_F_filt.fastq.gz"))
filtRs <- file.path(path, "filtered", paste0(sample.names, "_R_filt.fastq.gz"))
names(filtFs) <- sample.names
names(filtRs) <- sample.names

truncLenR1 <- 250
truncLenR2 <- 250
maxEER1 <- 2 # Default 2
maxEER2 <- 2 # Default 2

out <- filterAndTrim(fnFs, filtFs, fnRs, filtRs, truncLen=c(truncLenR1,truncLenR2),
                     maxN=0, maxEE=c(maxEER1,maxEER2), truncQ=2, rm.phix=TRUE,
                     compress=TRUE, multithread=TRUE) # On Windows set multithread=FALSE
head(out)
```

## Learn the Error Rates
```{r}
errF <- learnErrors(filtFs, multithread=TRUE) 
errR <- learnErrors(filtRs, multithread=TRUE) 
plotErrors(errF, nominalQ=FALSE)
ggsave("./Outputs/ErrF plot - SA_2-16s.png", width = 6, height = 4)
plotErrors(errR, nominalQ=FALSE)
ggsave("./Outputs/ErrR plot - SA_2-16s.png", width = 6, height = 4)
```

## Dereplication, Sample Inference, and Merging Reads
```{r}
# Loop taking care of dereplication, sample inference and merging paired reads
dadaFs <- vector("list", length(sample.names))
dadaRs <- vector("list", length(sample.names))
mergers <- vector("list", length(sample.names))
names(dadaFs) <- sample.names
names(dadaRs) <- sample.names
names(mergers) <- sample.names
for (sam in sample.names){
  cat("Processing:", sam, "\n")
  derepF <- derepFastq(filtFs[[sam]], verbose = TRUE)
  derepR <- derepFastq(filtRs[[sam]], verbose = TRUE)
  dadaFs[[sam]] <- dada(derepF, err=errF, multithread = TRUE)
  dadaRs[[sam]] <- dada(derepR, err=errR, multithread = TRUE)
  mergers[[sam]] <- mergePairs(dadaFs[[sam]], derepF, dadaRs[[sam]], derepR, verbose = TRUE)
}
head(mergers[[1]])
```

## Construct sequence table
```{r}
seqtab <- makeSequenceTable(mergers)
dim(seqtab) # 227 85537
saveRDS(seqtab, "./Outputs/seqtabs/seqtab_raw_SA_2-16s.RDS")

## Inspect distribution of sequence lengths
table(nchar(getSequences(seqtab)))
```

## Remove chimeras
```{r}
seqtab.nochim <- removeBimeraDenovo(seqtab, method="consensus", multithread=TRUE, verbose=TRUE) 
dim(seqtab.nochim)
saveRDS(seqtab.nochim, "./Outputs/seqtabs/seqtab_nochim_SA_2-16s.RDS")

sum(seqtab.nochim)/sum(seqtab)
```

## Track reads through pipeline
```{r}
getN <- function(x) sum(getUniques(x))
track <- cbind(out, sapply(dadaFs, getN), sapply(dadaRs, getN), sapply(mergers, getN), rowSums(seqtab.nochim))
# If processing a single sample, remove the sapply calls: e.g. replace sapply(dadaFs, getN) with getN(dadaFs)
colnames(track) <- c("input", "filtered", "denoisedF", "denoisedR", "merged", "nonchim")
rownames(track) <- sample.names
track
write.csv(track, file = "./Outputs/dada2track_SA_2-16s.csv")
```
```{r}
# Removing objects not required ahead to conserve RAM because some of the next steps are memory intensive
rm(dadaFs)
rm(dadaRs)
rm(derepF)
rm(derepR)
rm(errF)
rm(errR)
rm(mergers)
rm(out)
rm(seqtab)
```
```{r}
# Resume Point
#seqtab.nochim <- readRDS("./Outputs/Mangrove_16s/seqtabs/seqtab_nochim_SA-16s.RDS")
```

## Import metadata
```{r}
## Update this code section according to own run.
meta = read.csv("../../Resources/metadata-16s.csv", stringsAsFactors = FALSE)
row.names(meta) <- NULL
row.names(meta) <- meta$sampleName
row.names(seqtab.nochim)

# reorder metadata
meta = meta[order(row.names(meta)),]
meta = meta[rownames(meta) %in% rownames(seqtab.nochim),]
identical(rownames(meta), rownames(seqtab.nochim))
```

## Remove contaminants using controls
```{r}
library(decontam); packageVersion("decontam")

# Find controlsamples (extraction negatives)
meta$controls <- meta$site == "Blank"

# Find contaminants
contams = isContaminant(seqtab.nochim, neg = meta$controls, normalize = TRUE)
table(contams$contaminant)
write.csv(contams, file = "./Outputs/likely_contaminants-SA_2-16s.csv", row.names = TRUE)

# Remove them
seqtab.nochim = seqtab.nochim[meta$controls == FALSE,]
meta = meta[meta$controls == FALSE,]

saveRDS(meta, file = "./Outputs/final_meta-SA_2-16s.RDS")
```

## Assign Taxonomy
```{r}
taxa <- assignTaxonomy(seqtab.nochim, "../../04_Data/tax/silva_nr99_v138.1_train_set.fa.gz", multithread=TRUE) # CHANGE ME to taxa file location.
taxa <- addSpecies(taxa, "../../04_Data/tax/silva_species_assignment_v138.1.fa.gz") # Species level if required but memory intensive.

write.csv(as.data.frame(seqtab.nochim), file = "./Outputs/SeqTable_no-chimera_no-contams-SA_2-16s.csv", row.names = TRUE, quote = FALSE)
saveRDS(seqtab.nochim, file = "./Outputs/seqtabs/clean_dada2_seqtable-SA_2-16s.RDS")
saveRDS(taxa, file = "./Outputs/Silva_Taxonomy_from_dada2-SA_2-16s.RDS")

# Removing Mitochondria and Chloroplast as we are only analysing bacteria
#seqtab.nochim <- readRDS(file = "./Outputs/Mangrove_16s/seqtabs/clean_dada2_seqtable-SA_2-16s.RDS")
#taxa <- readRDS(file = "./Outputs/Mangrove_16s/Silva_Taxonomy_from_dada2-SA_2-16s.RDS")

# Remove non-bacterial samples
is.bacteria <- taxa[,"Kingdom"] %in% "Bacteria"
taxa <- taxa[is.bacteria,]
seqtab.bacteria <- seqtab.nochim[,is.bacteria]

# Remove "mitochondria" taxa
is.mitochon <- taxa[,"Family"] %in% "Mitochondria"
taxa <- taxa[!is.mitochon,]
seqtab.nomitochon <- seqtab.bacteria[,!is.mitochon]

# Remove "Chloroplast" taxa
is.chloro <- taxa[,"Order"] %in% "Chloroplast"
taxa <- taxa[!is.chloro,]
seqtab.nochloro <- seqtab.nomitochon[,!is.chloro]

is.chloro <- taxa[,"Class"] %in% "Chloroplast"
taxa <- taxa[!is.chloro,]
seqtab.nochloro <- seqtab.nochloro[,!is.chloro]

saveRDS(seqtab.nochloro, file = "./Outputs/seqtabs/final_clean_dada2_seqtable-SA_2-16s.RDS")
saveRDS(taxa, file = "./Outputs/final_Silva_Taxonomy_from_dada2-SA_2-16s.RDS")
```

## Adding Read Counts for new steps
```{r}
nochim <- rowSums(seqtab.nochim)
bacteria <- rowSums(seqtab.bacteria)
nomitochon <- rowSums(seqtab.nomitochon)
nochloro <- rowSums(seqtab.nochloro)
netloss <- (nochim-nochloro)/nochim
track_decontam <- data.frame(nochim, bacteria, nomitochon, nochloro, netloss)
write.csv(track_decontam, file = "./Outputs/read_counts_at_each_step_after_decontam-SA_2-16s.csv", row.names = TRUE)
track_decontam
```



# Seagrass 16s

# EA
```{r}
getwd()
path <- "../../04_Data/Seagrass_PNG_16s/EA-16s" # CHANGE ME to the directory containing the fastq files after unzipping.
list.files(path)
```
```{r}
getwd()
# Forward and reverse fastq filenames have format: SAMPLENAME_1.fastq and SAMPLENAME_2.fastq
fnFs <- sort(list.files(path, pattern="_1.fastq.gz", full.names = TRUE))
fnRs <- sort(list.files(path, pattern="_2.fastq.gz", full.names = TRUE))
# Extract sample names, assuming filenames have format: SAMPLENAME_1.fastq
sample.names <- sapply(strsplit(basename(fnFs), "_1.fastq.gz"), `[`, 1)
```

## Quality Profiles
```{r}
plotQualityProfile(fnFs[11:12])
ggsave("./Outputs/Quality plot F - EA-16s.png", width = 6, height = 4)
plotQualityProfile(fnRs[11:12])
ggsave("./Outputs/Quality plot R - EA-16s.png", width = 6, height = 4)
```
We trim at 250, 250.

## Filtering and Trimming
```{r}
# Place filtered files in filtered/ subdirectory
filtFs <- file.path(path, "filtered", paste0(sample.names, "_F_filt.fastq.gz"))
filtRs <- file.path(path, "filtered", paste0(sample.names, "_R_filt.fastq.gz"))
names(filtFs) <- sample.names
names(filtRs) <- sample.names

truncLenR1 <- 250
truncLenR2 <- 250
maxEER1 <- 2 # Default 2
maxEER2 <- 2 # Default 2

out <- filterAndTrim(fnFs, filtFs, fnRs, filtRs, truncLen=c(truncLenR1,truncLenR2),
                     maxN=0, maxEE=c(maxEER1,maxEER2), truncQ=2, rm.phix=TRUE,
                     compress=TRUE, multithread=TRUE) # On Windows set multithread=FALSE
head(out)
```

## Learn the Error Rates
```{r}
errF <- learnErrors(filtFs, multithread=TRUE) 
errR <- learnErrors(filtRs, multithread=TRUE) 
plotErrors(errF, nominalQ=FALSE)
ggsave("./Outputs/ErrF plot - EA-16s.png", width = 6, height = 4)
plotErrors(errR, nominalQ=FALSE)
ggsave("./Outputs/ErrR plot - EA-16s.png", width = 6, height = 4)
```

## Dereplication, Sample Inference, and Merging Reads
```{r}
# Loop taking care of dereplication, sample inference and merging paired reads
dadaFs <- vector("list", length(sample.names))
dadaRs <- vector("list", length(sample.names))
mergers <- vector("list", length(sample.names))
names(dadaFs) <- sample.names
names(dadaRs) <- sample.names
names(mergers) <- sample.names
for (sam in sample.names){
  cat("Processing:", sam, "\n")
  derepF <- derepFastq(filtFs[[sam]], verbose = TRUE)
  derepR <- derepFastq(filtRs[[sam]], verbose = TRUE)
  dadaFs[[sam]] <- dada(derepF, err=errF, multithread = TRUE)
  dadaRs[[sam]] <- dada(derepR, err=errR, multithread = TRUE)
  mergers[[sam]] <- mergePairs(dadaFs[[sam]], derepF, dadaRs[[sam]], derepR, verbose = TRUE)
}
head(mergers[[1]])
```

## Construct sequence table
```{r}
seqtab <- makeSequenceTable(mergers)
dim(seqtab) # 227 85537
saveRDS(seqtab, "./Outputs/seqtabs/seqtab_raw_EA-16s.RDS")

## Inspect distribution of sequence lengths
table(nchar(getSequences(seqtab)))
```

## Remove chimeras
```{r}
seqtab.nochim <- removeBimeraDenovo(seqtab, method="consensus", multithread=TRUE, verbose=TRUE) 
dim(seqtab.nochim)
saveRDS(seqtab.nochim, "./Outputs/seqtabs/seqtab_nochim_EA-16s.RDS")

sum(seqtab.nochim)/sum(seqtab)
```

## Track reads through pipeline
```{r}
getN <- function(x) sum(getUniques(x))
track <- cbind(out, sapply(dadaFs, getN), sapply(dadaRs, getN), sapply(mergers, getN), rowSums(seqtab.nochim))
# If processing a single sample, remove the sapply calls: e.g. replace sapply(dadaFs, getN) with getN(dadaFs)
colnames(track) <- c("input", "filtered", "denoisedF", "denoisedR", "merged", "nonchim")
rownames(track) <- sample.names
track
write.csv(track, file = "./Outputs/dada2track_EA-16s.csv")
```
```{r}
# Removing objects not required ahead to conserve RAM because some of the next steps are memory intensive
rm(dadaFs)
rm(dadaRs)
rm(derepF)
rm(derepR)
rm(errF)
rm(errR)
rm(mergers)
rm(out)
rm(seqtab)
```
```{r}
# Resume Point
#seqtab.nochim <- readRDS("./Outputs/Seagrass_16s/seqtabs/seqtab_nochim_EA-16s.RDS")
```

## Import metadata
```{r}
## Update this code section according to own run.
meta = read.csv("../../Resources/metadata-16s.csv", stringsAsFactors = FALSE)
row.names(meta) <- NULL
row.names(meta) <- meta$sampleName
row.names(seqtab.nochim)

# reorder metadata
meta = meta[order(row.names(meta)),]
meta = meta[rownames(meta) %in% rownames(seqtab.nochim),]
identical(rownames(meta), rownames(seqtab.nochim))
```

## Remove contaminants using controls
```{r}
library(decontam); packageVersion("decontam")

# Find controlsamples (extraction negatives)
meta$controls <- meta$site == "Blank"

# Find contaminants
contams = isContaminant(seqtab.nochim, neg = meta$controls, normalize = TRUE)
table(contams$contaminant)
write.csv(contams, file = "./Outputs/likely_contaminants-EA-16s.csv", row.names = TRUE)

# Remove them
seqtab.nochim = seqtab.nochim[meta$controls == FALSE,]
meta = meta[meta$controls == FALSE,]

saveRDS(meta, file = "./Outputs/final_meta-EA-16s.RDS")
```

## Assign Taxonomy
```{r}
taxa <- assignTaxonomy(seqtab.nochim, "../../04_Data/tax/silva_nr99_v138.1_train_set.fa.gz", multithread=TRUE) # CHANGE ME to taxa file location.
# taxa <- addSpecies(taxa, "../../04_Data/tax/silva_species_assignment_v138.1.fa.gz") # Species level if required but memory intensive.

write.csv(as.data.frame(seqtab.nochim), file = "./Outputs/SeqTable_no-chimera_no-contams-EA-16s.csv", row.names = TRUE, quote = FALSE)
saveRDS(seqtab.nochim, file = "./Outputs/seqtabs/clean_dada2_seqtable-EA-16s.RDS")
saveRDS(taxa, file = "./Outputs/Silva_Taxonomy_from_dada2-EA-16s.RDS")

# Removing Mitochondria and Chloroplast as we are only analysing bacteria
#seqtab.nochim <- readRDS(file = "./Outputs/Seagrass_16s/seqtabs/clean_dada2_seqtable-EA-16s.RDS")
#taxa <- readRDS(file = "./Outputs/Seagrass_16s/Silva_Taxonomy_from_dada2-EA-16s.RDS")

# Remove non-bacterial samples
is.bacteria <- taxa[,"Kingdom"] %in% "Bacteria"
taxa <- taxa[is.bacteria,]
seqtab.bacteria <- seqtab.nochim[,is.bacteria]

# Remove "mitochondria" taxa
is.mitochon <- taxa[,"Family"] %in% "Mitochondria"
taxa <- taxa[!is.mitochon,]
seqtab.nomitochon <- seqtab.bacteria[,!is.mitochon]

# Remove "Chloroplast" taxa
is.chloro <- taxa[,"Order"] %in% "Chloroplast"
taxa <- taxa[!is.chloro,]
seqtab.nochloro <- seqtab.nomitochon[,!is.chloro]

is.chloro <- taxa[,"Class"] %in% "Chloroplast"
taxa <- taxa[!is.chloro,]
seqtab.nochloro <- seqtab.nochloro[,!is.chloro]

saveRDS(seqtab.nochloro, file = "./Outputs/seqtabs/final_clean_dada2_seqtable-EA-16s.RDS")
saveRDS(taxa, file = "./Outputs/final_Silva_Taxonomy_from_dada2-EA-16s.RDS")
```

## Adding Read Counts for new steps
```{r}
nochim <- rowSums(seqtab.nochim)
bacteria <- rowSums(seqtab.bacteria)
nomitochon <- rowSums(seqtab.nomitochon)
nochloro <- rowSums(seqtab.nochloro)
netloss <- (nochim-nochloro)/nochim
track_decontam <- data.frame(nochim, bacteria, nomitochon, nochloro, netloss)
write.csv(track_decontam, file = "./Outputs/read_counts_at_each_step_after_decontam-EA-16s.csv", row.names = TRUE)
track_decontam
```


# TH
```{r}
getwd()
path <- "../../04_Data/Seagrass_PNG_16s/TH-16s" # CHANGE ME to the directory containing the fastq files after unzipping.
list.files(path)
```
```{r}
getwd()
# Forward and reverse fastq filenames have format: SAMPLENAME_1.fastq and SAMPLENAME_2.fastq
fnFs <- sort(list.files(path, pattern="_1.fastq.gz", full.names = TRUE))
fnRs <- sort(list.files(path, pattern="_2.fastq.gz", full.names = TRUE))
# Extract sample names, assuming filenames have format: SAMPLENAME_1.fastq
sample.names <- sapply(strsplit(basename(fnFs), "_1.fastq.gz"), `[`, 1)
```

## Quality Profiles
```{r}
plotQualityProfile(fnFs[11:12])
ggsave("./Outputs/Quality plot F - TH-16s.png", width = 6, height = 4)
plotQualityProfile(fnRs[11:12])
ggsave("./Outputs/Quality plot R - TH-16s.png", width = 6, height = 4)
```
We trim at 250, 250.

## Filtering and Trimming
```{r}
# Place filtered files in filtered/ subdirectory
filtFs <- file.path(path, "filtered", paste0(sample.names, "_F_filt.fastq.gz"))
filtRs <- file.path(path, "filtered", paste0(sample.names, "_R_filt.fastq.gz"))
names(filtFs) <- sample.names
names(filtRs) <- sample.names

truncLenR1 <- 250
truncLenR2 <- 250
maxEER1 <- 2 # Default 2
maxEER2 <- 2 # Default 2

out <- filterAndTrim(fnFs, filtFs, fnRs, filtRs, truncLen=c(truncLenR1,truncLenR2),
                     maxN=0, maxEE=c(maxEER1,maxEER2), truncQ=2, rm.phix=TRUE,
                     compress=TRUE, multithread=TRUE) # On Windows set multithread=FALSE
head(out)
```

## Learn the Error Rates
```{r}
errF <- learnErrors(filtFs, multithread=TRUE) 
errR <- learnErrors(filtRs, multithread=TRUE) 
plotErrors(errF, nominalQ=FALSE)
ggsave("./Outputs/ErrF plot - TH-16s.png", width = 6, height = 4)
plotErrors(errR, nominalQ=FALSE)
ggsave("./Outputs/ErrR plot - TH-16s.png", width = 6, height = 4)
```

## Dereplication, Sample Inference, and Merging Reads
```{r}
# Loop taking care of dereplication, sample inference and merging paired reads
dadaFs <- vector("list", length(sample.names))
dadaRs <- vector("list", length(sample.names))
mergers <- vector("list", length(sample.names))
names(dadaFs) <- sample.names
names(dadaRs) <- sample.names
names(mergers) <- sample.names
for (sam in sample.names){
  cat("Processing:", sam, "\n")
  derepF <- derepFastq(filtFs[[sam]], verbose = TRUE)
  derepR <- derepFastq(filtRs[[sam]], verbose = TRUE)
  dadaFs[[sam]] <- dada(derepF, err=errF, multithread = TRUE)
  dadaRs[[sam]] <- dada(derepR, err=errR, multithread = TRUE)
  mergers[[sam]] <- mergePairs(dadaFs[[sam]], derepF, dadaRs[[sam]], derepR, verbose = TRUE)
}
head(mergers[[1]])
```

## Construct sequence table
```{r}
seqtab <- makeSequenceTable(mergers)
dim(seqtab) # 227 85537
saveRDS(seqtab, "./Outputs/seqtabs/seqtab_raw_TH-16s.RDS")

## Inspect distribution of sequence lengths
table(nchar(getSequences(seqtab)))
```

## Remove chimeras
```{r}
seqtab.nochim <- removeBimeraDenovo(seqtab, method="consensus", multithread=TRUE, verbose=TRUE) 
dim(seqtab.nochim)
saveRDS(seqtab.nochim, "./Outputs/seqtabs/seqtab_nochim_TH-16s.RDS")

sum(seqtab.nochim)/sum(seqtab)
```

## Track reads through pipeline
```{r}
getN <- function(x) sum(getUniques(x))
track <- cbind(out, sapply(dadaFs, getN), sapply(dadaRs, getN), sapply(mergers, getN), rowSums(seqtab.nochim))
# If processing a single sample, remove the sapply calls: e.g. replace sapply(dadaFs, getN) with getN(dadaFs)
colnames(track) <- c("input", "filtered", "denoisedF", "denoisedR", "merged", "nonchim")
rownames(track) <- sample.names
track
write.csv(track, file = "./Outputs/dada2track_TH-16s.csv")
```
```{r}
# Removing objects not required ahead to conserve RAM because some of the next steps are memory intensive
rm(dadaFs)
rm(dadaRs)
rm(derepF)
rm(derepR)
rm(errF)
rm(errR)
rm(mergers)
rm(out)
rm(seqtab)
```
```{r}
# Resume Point
#seqtab.nochim <- readRDS("./Outputs/Seagrass_16s/seqtabs/seqtab_nochim_TH-16s.RDS")
```

## Import metadata
```{r}
## Update this code section according to own run.
meta = read.csv("../../Resources/metadata-16s.csv", stringsAsFactors = FALSE)
row.names(meta) <- NULL
row.names(meta) <- meta$sampleName
row.names(seqtab.nochim)

# reorder metadata
meta = meta[order(row.names(meta)),]
meta = meta[rownames(meta) %in% rownames(seqtab.nochim),]
identical(rownames(meta), rownames(seqtab.nochim))
```

## Remove contaminants using controls
```{r}
library(decontam); packageVersion("decontam")

# Find controlsamples (extraction negatives)
meta$controls <- meta$site == "Blank"

# Find contaminants
contams = isContaminant(seqtab.nochim, neg = meta$controls, normalize = TRUE)
table(contams$contaminant)
write.csv(contams, file = "./Outputs/likely_contaminants-TH-16s.csv", row.names = TRUE)

# Remove them
seqtab.nochim = seqtab.nochim[meta$controls == FALSE,]
meta = meta[meta$controls == FALSE,]

saveRDS(meta, file = "./Outputs/final_meta-TH-16s.RDS")
```

```{r}
rm(contams)
rm(meta)
rm(track)
saveRDS(seqtab.nochim, file = "./Outputs/seqtabs/clean_dada2_seqtable-TH-16s.RDS")
```

## Assign Taxonomy
```{r}
### START OF HPC CODE ###
taxa <- assignTaxonomy(seqtab.nochim, "../../04_Data/tax/silva_nr99_v138.1_train_set.fa.gz", multithread=TRUE) # CHANGE ME to taxa file location.
# taxa <- addSpecies(taxa, "../../04_Data/tax/silva_species_assignment_v138.1.fa.gz") # Species level if required but memory intensive.
### END OF HPC CODE ###
#taxa <- readRDS("./Outputs/Silva_Taxonomy_from_dada2-TH-16s.RDS")

write.csv(as.data.frame(seqtab.nochim), file = "./Outputs/SeqTable_no-chimera_no-contams-TH-16s.csv", row.names = TRUE, quote = FALSE)
saveRDS(taxa, file = "./Outputs/Silva_Taxonomy_from_dada2-TH-16s.RDS")

# Removing Mitochondria and Chloroplast as we are only analysing bacteria
#seqtab.nochim <- readRDS(file = "./Outputs/Seagrass_16s/seqtabs/clean_dada2_seqtable-TH-16s.RDS")
#taxa <- readRDS(file = "./Outputs/Seagrass_16s/Silva_Taxonomy_from_dada2-TH-16s.RDS")

# Remove non-bacterial samples
is.bacteria <- taxa[,"Kingdom"] %in% "Bacteria"
taxa <- taxa[is.bacteria,]
seqtab.bacteria <- seqtab.nochim[,is.bacteria]

# Remove "mitochondria" taxa
is.mitochon <- taxa[,"Family"] %in% "Mitochondria"
taxa <- taxa[!is.mitochon,]
seqtab.nomitochon <- seqtab.bacteria[,!is.mitochon]

# Remove "Chloroplast" taxa
is.chloro <- taxa[,"Order"] %in% "Chloroplast"
taxa <- taxa[!is.chloro,]
seqtab.nochloro <- seqtab.nomitochon[,!is.chloro]

is.chloro <- taxa[,"Class"] %in% "Chloroplast"
taxa <- taxa[!is.chloro,]
seqtab.nochloro <- seqtab.nochloro[,!is.chloro]

saveRDS(seqtab.nochloro, file = "./Outputs/seqtabs/final_clean_dada2_seqtable-TH-16s.RDS")
saveRDS(taxa, file = "./Outputs/final_Silva_Taxonomy_from_dada2-TH-16s.RDS")
```

## Adding Read Counts for new steps
```{r}
nochim <- rowSums(seqtab.nochim)
bacteria <- rowSums(seqtab.bacteria)
nomitochon <- rowSums(seqtab.nomitochon)
nochloro <- rowSums(seqtab.nochloro)
netloss <- (nochim-nochloro)/nochim
track_decontam <- data.frame(nochim, bacteria, nomitochon, nochloro, netloss)
write.csv(track_decontam, file = "./Outputs/read_counts_at_each_step_after_decontam-TH-16s.csv", row.names = TRUE)
track_decontam
```


